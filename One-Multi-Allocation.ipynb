{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wJMkTGlPB6XenF8eGHr2iEMmzEEKBYeQ","timestamp":1702747105997},{"file_id":"1MaH3lvza_gOCjKCDwxJ7O9olkOYR65EL","timestamp":1702489092590}],"authorship_tag":"ABX9TyPOot/rAxvWotzebWokmpm6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction Of One-Multi Solution\n","\n","**This strategy is based on the idea that rather than providing passengers with a direct flight to their destination, we will attempt to shorten their wait time by providing them with the option of connecting flights, which will shorten the total time. However, we are only allowing one connecting flight because providing more will lower passenger satisfaction.**"],"metadata":{"id":"JTn8b8b_dbIQ"}},{"cell_type":"markdown","source":["**Mount the drive here**"],"metadata":{"id":"yZTKyFpddVHG"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_-D07vyCwOI","executionInfo":{"status":"ok","timestamp":1702732811507,"user_tz":-330,"elapsed":20833,"user":{"displayName":"Team-69","userId":"15141329460336760271"}},"outputId":"2ca942b7-79c1-463a-887d-f43622b16b30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import datetime"],"metadata":{"id":"jlQZwyniEuWg","executionInfo":{"status":"ok","timestamp":1702732816866,"user_tz":-330,"elapsed":493,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### **Data Loading and Preprocessing Block**"],"metadata":{"id":"Qrp7QdIhT99l"}},{"cell_type":"code","source":["# Data Loading\n","\n","df_pnr_book = pd.read_csv(\"/content/drive/MyDrive/TEAM-69/Final Dataset/PNRB-ZZ-20231208_062017.csv\")\n","df_pnr_pass = pd.read_csv(\"/content/drive/MyDrive/TEAM-69/Final Dataset/PNRP-ZZ-20231208_111136.csv\")\n","df_schedule = pd.read_csv('/content/drive/MyDrive/TEAM-69/Final Dataset/SCH-ZZ-20231208_035117.csv')\n","df_inventory = pd.read_csv('/content/drive/MyDrive/TEAM-69/Final Dataset/INV-ZZ-20231208_041852.csv')\n","\n","# Data Preprocessing\n","\n","date_columns = ['DEP_DTML', 'ARR_DTML', 'DEP_DTMZ', 'ARR_DTMZ']\n","for column in date_columns:\n","    df_pnr_book[column] = pd.to_datetime(df_pnr_book[column], errors='coerce').dt.strftime('%m/%d/%Y %H:%M')\n","df_pnr_book['DEP_DT'] = pd.to_datetime(df_pnr_book['DEP_DT'], errors='coerce').dt.strftime('%m/%d/%Y')\n","#For Inventory\n","df_inventory['DepartureDate'] = pd.to_datetime(df_inventory['DepartureDate'], errors='coerce').dt.strftime('%m/%d/%Y')\n","date_columns = ['DepartureDateTime', 'ArrivalDateTime']\n","for column in date_columns:\n","    df_inventory[column] = pd.to_datetime(df_inventory[column], errors='coerce').dt.strftime('%Y/%m/%d %H:%M:%S')\n","date_columns = ['DepartureDateTime', 'ArrivalDateTime']\n","df_inventory[date_columns] = df_inventory[date_columns].apply(pd.to_datetime, format='%Y-%m-%d %H:%M:%S')"],"metadata":{"id":"8os7XIBaEu5T","executionInfo":{"status":"ok","timestamp":1702732827334,"user_tz":-330,"elapsed":5038,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### **Function Block for obtaining all the impacted PNRS resulting from a specific flight cancellation in the priority order determined by their score**\n"],"metadata":{"id":"kRwjxlKkUFRB"}},{"cell_type":"code","source":["def get_ITN_DEST(df):\n","    df[['SEG_SEQ', 'SEG_TOTAL']] = df[['SEG_SEQ', 'SEG_TOTAL']].apply(pd.to_numeric, errors='coerce')\n","    max_dest_per_recloc = df.loc[df['SEG_SEQ'] == df['SEG_TOTAL']].groupby('RECLOC')['DEST_CD'].first().reset_index()\n","    df = pd.merge(df, max_dest_per_recloc, on='RECLOC', how='left', suffixes=('', '_ITN_DEST'))\n","    return df\n","\n","def process_pnr_data(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date):\n","\n","    dept_time = df_schedule[(df_schedule['FlightNumber'] == flight_number) & (df_schedule['AircraftTailNumber'] == tail_number)]['DepartureTime'].iloc[0]\n","    date_time = date + ' ' + dept_time\n","    print(date_time)\n","\n","    def cal_affected_persons(flt_number, date_time):\n","        dict={}\n","        affect_persons = pd.DataFrame(columns=df_pnr_book.columns)\n","\n","        for i in range(len(df_pnr_book)):\n","            if df_pnr_book.loc[i, \"RECLOC\"] in dict.keys():\n","                dict[df_pnr_book.loc[i, \"RECLOC\"]] = max(dict[df_pnr_book.loc[i, \"RECLOC\"]], df_pnr_book.loc[i, \"SEG_SEQ\"])\n","            else:\n","                dict[df_pnr_book.loc[i, \"RECLOC\"]] = df_pnr_book.loc[i, \"SEG_SEQ\"]\n","\n","            if df_pnr_book.loc[i, \"FLT_NUM\"] == flt_number and df_pnr_book.loc[i, \"DEP_DTML\"] == date_time:\n","                affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","\n","\n","        li = []\n","        for i in range(len(affect_persons)):\n","            if(dict[affect_persons.iloc[i][\"RECLOC\"]]):\n","                li.append(dict[affect_persons.iloc[i][\"RECLOC\"]])\n","        affect_persons[\"MAX_SEG\"] = li\n","        return affect_persons\n","\n","    def calc_ssr(flight_number, date_time):\n","        affect_person = cal_affected_persons(flight_number, date_time)\n","        li = []\n","        for i in range(len(affect_person)):\n","            li.append(0)\n","        affect_person[\"count_ssr\"] = li\n","        for i in range(len(affect_person)):\n","            for j in range(len(df_pnr_pass)):\n","                if df_pnr_pass.loc[j, \"RECLOC\"] == affect_person.iloc[i][\"RECLOC\"]:\n","                    if pd.notna(df_pnr_pass[\"SSR_CODE_CD1\"][j]) or pd.notna(df_pnr_pass[\"SPECIAL_NAME_CD2\"][j] or pd.notna(df_pnr_pass[\"SPECIAL_NAME_CD1\"][j])):\n","                        affect_person.iloc[i][\"count_ssr\"] += 1\n","        return affect_person\n","\n","    def score_eval(affect_PNR):\n","        score = 0\n","        score += 200 * affect_PNR.loc[\"count_ssr\"] + 50 * affect_PNR.loc[\"PAX_CNT\"]\n","        score += 100 * (affect_PNR.loc[\"MAX_SEG\"] - affect_PNR.loc[\"SEG_SEQ\"])\n","        score_dict = {'A': 'J', 'D': 'J', 'J': 'J', 'B': 'F', 'F': 'F', 'S': 'Y', 'V': 'Y', 'W': 'Y', 'Z': 'Y', 'O': 'Y',\n","                      'S': 'Y', 'T': 'Y', 'U': 'Y', 'M': 'Y', 'N': 'Y', 'Y': 'Y'}\n","        if affect_PNR.loc[\"COS_CD\"] not in score_dict.keys():\n","            score += 500\n","        elif affect_PNR.loc[\"COS_CD\"] == 'J' or score_dict[affect_PNR.loc[\"COS_CD\"]] == 'J':\n","            score += 2000\n","        elif affect_PNR.loc[\"COS_CD\"] == \"F\" or score_dict[affect_PNR.loc[\"COS_CD\"]] == \"F\":\n","            score += 1700\n","        elif affect_PNR.loc[\"COS_CD\"] == \"Y\" or score_dict[affect_PNR.loc[\"COS_CD\"]] == \"Y\":\n","            score += 1500\n","        elif affect_PNR.loc[\"COS_CD\"] in [\"A\", \"C\", \"K\"]:\n","            score += 800\n","        return score\n","\n","    def score(flight, data_time):\n","        affect_PNR = calc_ssr(flight, data_time)\n","        pnr_ranking = pd.DataFrame(columns=affect_PNR.columns.tolist() + ['score'])\n","\n","        for i in range(len(affect_PNR)):\n","            score_val = score_eval(affect_PNR.iloc[i])\n","            affect_row = list(affect_PNR.iloc[i])\n","            affect_row.append(score_val)\n","            pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","\n","        sorted_pnr_ranking = pnr_ranking.sort_values(by='score', ascending=False)\n","        return sorted_pnr_ranking\n","\n","    return score(flight_number, date_time)\n","\n","def get_cluster_rank(affect_sorted_PNR):\n","    cluster_means = affect_sorted_PNR.groupby('DEST_CD_ITN_DEST')['score'].mean()\n","    rank_mapping = {cluster: rank for rank, (cluster, _) in enumerate(cluster_means.sort_values(ascending=False).iteritems(), start=1)}\n","    affect_sorted_PNR['CLUSTER_RANK'] = affect_sorted_PNR['DEST_CD_ITN_DEST'].map(rank_mapping)\n","    return affect_sorted_PNR\n","\n","def get_pnr_affected(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date):\n","    df_pnr_book = get_ITN_DEST(df_pnr_book)\n","    affect_sorted_PNR = process_pnr_data(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date)\n","    final_affected_PNR = get_cluster_rank(affect_sorted_PNR)\n","\n","    return final_affected_PNR"],"metadata":{"id":"5Ar2iH9uX_RS","executionInfo":{"status":"ok","timestamp":1702733319467,"user_tz":-330,"elapsed":453,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## **INPUT BLOCK**\n"],"metadata":{"id":"yUI0EitjTo2M"}},{"cell_type":"code","source":["flight_number = int(input(\"Enter the flight number: \"))\n","tail_number = input(\"Enter the tail number: \")\n","date = input(\"Enter the date (MM/DD/YYYY): \")\n","affect_sorted_PNR = get_pnr_affected(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date)"],"metadata":{"id":"dq7luQ4IH_ER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Storing Affected PNR Record**"],"metadata":{"id":"g-YgJ7VDVhic"}},{"cell_type":"code","source":["affect_sorted_PNR.to_csv('/content/affected_PNR.csv', index=False)"],"metadata":{"id":"Nn02vVS1_oWG","executionInfo":{"status":"ok","timestamp":1702733519281,"user_tz":-330,"elapsed":456,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Generating Feasiable Flights from Source to conncetion and connection to destination\n","\n","Using the Branch Prunning Algorithm and DAG (Direct Acyclic Graph) to schedule a connecting flight between the source and the destination in order to avoid taking the duplicated and impractical route\n"],"metadata":{"id":"G9ZNvaULTenR"}},{"cell_type":"code","source":["df=pd.read_csv(\"/content/drive/MyDrive/TEAM-69/Final Dataset/SCH-ZZ-20231208_035117.csv\")\n","dff=pd.read_csv(\"/content/drive/MyDrive/TEAM-69/Final Dataset/INV-ZZ-20231208_041852.csv\")\n","\n","def source_flights(flt_num,tale_num,date):\n","  for i in range(len(df)):\n","    if(flt_num==df.loc[i][\"FlightNumber\"] and tale_num==df.loc[i][\"AircraftTailNumber\"]):\n","      return df.iloc[i]\n","  return -1\n","\n","def conv_dep_time(a):\n","  k=0\n","  li=[]\n","  t=\"\"\n","  for i in range(len(a)):\n","    if(a[i]==\"'\"):\n","      k=(k+1)%2\n","      if(k==0):\n","        li.append(t)\n","        t=\"\"\n","    else:\n","      if(k==1):\n","        t+=a[i]\n","  return li\n","\n","class DirectedWeightedGraph:\n","    def __init__(self):\n","        self.graph = {}\n","\n","    def add_vertex(self, vertex):\n","        if vertex not in self.graph:\n","            self.graph[vertex] = []\n","\n","    def add_edge(self, src, dest, weight):\n","        if src in self.graph:\n","            self.graph[src].append([dest, weight])\n","        else:\n","            self.graph[src] = [[dest, weight]]\n","\n","    def get_adjacency_elements(self, vertex):\n","        adjacency_elements = set()\n","        if vertex in self.graph:\n","            adjacency_list = self.graph[vertex]\n","            for neighbor, _ in adjacency_list:\n","                adjacency_elements.add(neighbor)\n","        else:\n","            print(f'Vertex {vertex} not found in the graph.')\n","\n","        return list(adjacency_elements)\n","\n","    def edges_to_dataframe(self):\n","        merged_row_df = pd.DataFrame()\n","        for vertex in self.graph:\n","            for edge in self.graph[vertex]:\n","                dest, weight = edge\n","                merged_df = pd.concat([weight[0], weight[1]], axis=0)# Remove duplicate columns\n","                merged_df = pd.DataFrame(merged_df).T\n","                merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n","                merged_row_df = merged_row_df.append(merged_df, ignore_index=True)\n","        return merged_row_df\n","\n","\n","    def display(self):\n","        for vertex in self.graph:\n","            for edge in self.graph[vertex]:\n","                print(vertex, '->',''.join(map(str, edge[0])))\n","            # print(vertex, '->', ' -> '.join(map(str, self.graph[vertex])))\n","\n","    def delete_vertices_without_elements(self, element1, element2):\n","        vertices_to_delete = []\n","        for vertex in self.graph:\n","            if(vertex!=element1 and vertex!=element2):\n","                adjacency = [edge[0] for edge in self.graph[vertex]]\n","                print(vertex)\n","                if(element2 not in adjacency):\n","                    vertices_to_delete.append(vertex)\n","                if(vertex not in self.get_adjacency_elements(element1)):\n","                    vertices_to_delete.append(vertex)\n","        for vertex in vertices_to_delete:\n","            del self.graph[vertex]\n","        for vertex in self.graph:\n","            self.graph[vertex] = [(dest, weight) for dest, weight in self.graph[vertex] if dest not in vertices_to_delete]\n","\n","from datetime import datetime, timedelta\n","def is_within_n_days(departure_datetime, target_datetime, n):\n","    datetime_format = \"%m/%d/%Y %H:%M\"\n","\n","    departure_datetime = datetime.strptime(departure_datetime, datetime_format)\n","    target_datetime = datetime.strptime(target_datetime, datetime_format)\n","\n","    days_difference = (target_datetime - departure_datetime).days\n","\n","    return 0 <= days_difference <= n\n","\n","def Graph_Flight_Formulation(df,dff,Soure,Destination,DD,n):\n","    for i in range(len(df)):\n","        print(i)\n","        if(df.loc[i][\"DepartureAirport\"].replace(\" \",\"\")==Source.replace(\" \",\"\") and df.loc[i][\"ArrivalAirport\"].replace(\" \",\"\")!=Destination.replace(\" \",\"\")):\n","            for j in range(len(dff)):\n","                for time in conv_dep_time(df.loc[i][\"DepartureDates\"]):\n","                    if(dff.loc[j][\"ScheduleId\"]==df.loc[i][\"ScheduleID\"] and dff.loc[j][\"DepartureDate\"]==time):\n","                        # print(df.loc[i][\"DepartureAirport\"],df.loc[i][\"ArrivalAirport\"])\n","                        g.add_edge(df.loc[i][\"DepartureAirport\"].replace(\" \",\"\"),df.loc[i][\"ArrivalAirport\"].replace(\" \",\"\"),[df.loc[i],dff.loc[j]])\n","                        g.add_vertex(df.loc[i][\"ArrivalAirport\"].replace(\" \",\"\"))\n","        if(df.loc[i][\"DepartureAirport\"].replace(\" \",\"\")!=Source.replace(\" \",\"\") and df.loc[i][\"ArrivalAirport\"].replace(\" \",\"\")==Destination.replace(\" \",\"\")):\n","            for k in range(len(dff)):\n","                for time1 in conv_dep_time(df.loc[i][\"DepartureDates\"]):\n","                    # print(dff.loc[k][\"DepartureDate\"],time1)\n","                    if(dff.loc[k][\"ScheduleId\"]==df.loc[i][\"ScheduleID\"] and dff.loc[k][\"DepartureDate\"]==time1):\n","                        # print(df.loc[i][\"DepartureAirport\"],df.loc[i][\"ArrivalAirport\"])\n","                        g.add_edge(df.loc[i][\"DepartureAirport\"].replace(\" \",\"\"),df.loc[i][\"ArrivalAirport\"].replace(\" \",\"\"),[df.loc[i],dff.loc[k]])\n","                        g.add_vertex(df.loc[i][\"ArrivalAirport\"].replace(\" \",\"\"))\n","    g.delete_vertices_without_elements(Source.replace(\" \",\"\"),Destination.replace(\" \",\"\"))\n","    res=(g.edges_to_dataframe())\n","    srcc=pd.DataFrame(columns=res.columns)\n","    destc=pd.DataFrame(columns=res.columns)\n","    for i in range(len(res)):\n","        if(res.loc[i][\"DepartureAirport\"].replace(\" \",\"\")==Source.replace(\" \",\"\")):\n","            srcc=srcc.append(res.loc[i])\n","        else:\n","            destc=destc.append(res.loc[i])\n","    for i in range(len(srcc)):\n","        t=\"\"\n","        t+=srcc.loc[i][\"DepartureDate\"]\n","        t+=\" \"\n","        t+=srcc.loc[i][\"DepartureTime\"]\n","        if not is_within_n_days(DD,t,n):\n","            srcc=srcc.drop(i)\n","    return srcc,destc"],"metadata":{"id":"3l-BSHPoTPuy","executionInfo":{"status":"ok","timestamp":1702736276402,"user_tz":-330,"elapsed":465,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":["**Source and Destination of Disturbed Iternary**"],"metadata":{"id":"xOKSLLr7Wzyf"}},{"cell_type":"code","source":["ans=source_flights(flight_number,tail_number,date)\n","Source=ans[\"DepartureAirport\"]\n","Destination=ans[\"ArrivalAirport\"]\n","DD=date+\" \"+ans[\"DepartureTime\"]\n","print(\"Disturbed Iternary\",Source,\"-->\",Destination)"],"metadata":{"id":"gAQ5heQPT5su"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Getting Possible flights from source to connecting within n days of departure that is matching_s2c_flights\n","\n","All possible flight from connecting to destination that is mamatching_c2d_flights"],"metadata":{"id":"wICNiweqXRac"}},{"cell_type":"code","source":["g=DirectedWeightedGraph()\n","n=int(input(\"Minimum number of days for accomodation=\"))\n","matching_s2c_flights,matching_s2d_flights=Graph_Flight_Formulation(df,dff,Source,Destination,DD,n)\n","matching_s2c_flights=matching_s2c_flights.sort_values(by='DepartureDateTime')"],"metadata":{"id":"Vj132Qe4URQz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Scheduling of PNR into connecting Flights\n","\n","**Affected PNR distribution into two flights based on class and arrival/departure time differences One involves connecting from the source to the destination, while the other is the opposite.**"],"metadata":{"id":"kjZbNCrAY7Tx"}},{"cell_type":"code","source":["# Assuming 'affect_sorted_PNR' is your DataFrame\n","df_FC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'FirstClass'].copy()\n","df_BC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'BusinessClass'].copy()\n","df_PC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'PremiumEconomyClass'].copy()\n","df_EC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'EconomyClass'].copy()\n","print(\"passenger total in different class = \",df_FC.shape, df_BC.shape, df_PC.shape, df_EC.shape)\n","def knapsack1(left_seats, n, li, PNR_df, memo):\n","    if n == 0 or left_seats == 0:\n","        return left_seats, li\n","\n","    # Check if the result is already memoized\n","    if (left_seats, n) in memo:\n","        return memo[(left_seats, n)]\n","\n","    if left_seats >= PNR_df.iloc[n-1][\"PAX_CNT\"]:\n","        # Recursively compute the result and memoize it\n","        result1 = knapsack1(left_seats, n-1, li, PNR_df, memo)\n","        result2 = knapsack1(left_seats - PNR_df.iloc[n-1][\"PAX_CNT\"], n-1, li + [PNR_df.iloc[n-1][\"RECLOC\"]], PNR_df, memo)\n","        result = min(result1, result2, key=lambda x: x[0])\n","    else:\n","        result = knapsack1(left_seats, n-1, li, PNR_df, memo)\n","\n","    # Memoize the result\n","    memo[(left_seats, n)] = result\n","\n","    return result\n","\n","def delete_entry(to_delete, dataframe):\n","    for i in to_delete:\n","        dataframe.drop(dataframe[dataframe[\"RECLOC\"]==i].index, inplace=True, axis=0)\n","    return dataframe\n","\n","def all_flights_knapsack_for_same_class1(df_PNR, flights, cls):\n","    allocated_dict = {}\n","    for i in range(len(flights)):\n","        seats_left, allocated_PNRs = knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR, {})\n","\n","        # Update the values in the flights DataFrame\n","        temp_column = cls+\"_AvailableInventory\"\n","        temp = flights.iloc[i][temp_column]\n","        column_index = flights.columns.get_loc(temp_column)\n","        flights.iat[i, column_index] = seats_left\n","        flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","        df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","        allocated_dict[flights.iloc[i][\"InventoryId\"]] = [(pnr, cls,flights.iloc[i][\"DepartureDateTime\"],flights.iloc[i][\"ArrivalDateTime\"],flights.iloc[i][\"ArrivalAirport\"]) for pnr in allocated_PNRs]\n","\n","    return allocated_dict\n","\n","def merge_dict(dict1,dict2):\n","    list1=dict1.keys()\n","\n","    for i in list1:\n","        dict1[i]=dict1[i]+dict2[i]\n","    return dict1\n","\n","def convert_dict_to_dataframe(allocated_dict):\n","    data = []\n","\n","    for inventory_id, allocations in allocated_dict.items():\n","        for allocation in allocations:\n","            pnr, class_name , DT , AT, AA = allocation\n","            data.append({'PNR': pnr, 'InventoryID': inventory_id, 'New_ClassName': class_name, 'DT':DT,'AT':AT,\"AA\":AA})\n","\n","    df = pd.DataFrame(data)\n","    return df\n","\n","def complete_allocation(df_FC_copy,df_BC_copy,df_PE_copy,df_EC_copy,flights):\n","    print(flights)\n","    FC_allocation=all_flights_knapsack_for_same_class1(df_FC_copy, flights, \"FC\")\n","    BC_allocation=all_flights_knapsack_for_same_class1(df_BC_copy, flights, \"BC\")\n","    PE_allocation=all_flights_knapsack_for_same_class1(df_PE_copy, flights, \"PC\")\n","    EC_allocation=all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"EC\")\n","    # print(PE_allocation)\n","    # print(EC_allocation)\n","    # print(BC_allocation)\n","    # print(FC_allocation)\n","    if not df_FC_copy.empty:\n","        PE_allocation.update(all_flights_knapsack_for_same_class1(df_FC_copy, flights, \"PC\"))\n","        EC_allocation.update(all_flights_knapsack_for_same_class1(df_FC_copy, flights, \"EC\"))\n","    if not df_BC_copy.COS_CD.empty:\n","        EC_allocation.update(all_flights_knapsack_for_same_class1(df_BC_copy, flights, \"EC\"))\n","    if not df_PE_copy.empty:\n","        FC_allocation.update(all_flights_knapsack_for_same_class1(df_PE_copy, flights, \"FC\"))\n","    if not df_EC_copy.empty:\n","        FC_allocation.update(all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"FC\"))\n","        BC_allocation.update(all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"BC\"))\n","        PE_allocation.update(all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"PC\"))\n","\n","\n","    df=convert_dict_to_dataframe(FC_allocation)\n","    df=pd.concat([df, convert_dict_to_dataframe(BC_allocation)], ignore_index=True)\n","    df=pd.concat([df, convert_dict_to_dataframe(PE_allocation)], ignore_index=True)\n","    df=pd.concat([df, convert_dict_to_dataframe(EC_allocation)], ignore_index=True)\n","    print(df.shape,\"#\")\n","    return df"],"metadata":{"id":"u9VRY2wiR0Fd","executionInfo":{"status":"ok","timestamp":1702736808525,"user_tz":-330,"elapsed":523,"user":{"displayName":"Team-69","userId":"15141329460336760271"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bad3cce4-abe7-4cd3-b7bb-1e92df291064"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["passenger total in different class =  (5, 22) (9, 22) (7, 22) (11, 22)\n"]}]},{"cell_type":"markdown","source":["## **It return Schdule of affected PNR in dfn from source to connecting**"],"metadata":{"id":"gKOwNu6saLcs"}},{"cell_type":"code","source":["dfn=complete_allocation(df_FC,df_BC,df_PC,df_EC,matching_s2c_flights)\n","dfn"],"metadata":{"id":"EVV-2xu6STZg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Merging the Schedule of PNR with thier details and clustering them on basis of the invetory ID of connecting flight from source to destination as a dataframe in a list named grouped_dfs**"],"metadata":{"id":"oQtFuU0knfiG"}},{"cell_type":"code","source":["final_df = pd.merge(dfn, affect_sorted_PNR, left_on='PNR', right_on='RECLOC', how='inner')\n","grouped_dfs = [group_df for _, group_df in final_df.groupby('InventoryID')]"],"metadata":{"id":"9smLdQq6leux","executionInfo":{"status":"ok","timestamp":1702736821515,"user_tz":-330,"elapsed":719,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":["### **Scheduling Flight of impacted PNR from connection to Destination**"],"metadata":{"id":"3_H9_74yoQ7S"}},{"cell_type":"code","source":["def change_format(date_str):\n","    date_obj = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n","    formatted_date = date_obj.strftime('%m/%d/%Y %H:%M')\n","    return formatted_date\n"],"metadata":{"id":"tmDTXmf9J2wC","executionInfo":{"status":"ok","timestamp":1702737280526,"user_tz":-330,"elapsed":432,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":132,"outputs":[]},{"cell_type":"code","source":["def process_group(group_df, matching_s2d_flights):\n","    # Separate the group_df based on 'COS_CD'\n","    df_FC = group_df[group_df['COS_CD'] == 'FirstClass'].copy()\n","    df_BC = group_df[group_df['COS_CD'] == 'BusinessClass'].copy()\n","    df_PC = group_df[group_df['COS_CD'] == 'PremiumEconomyClass'].copy()\n","    df_EC = group_df[group_df['COS_CD'] == 'EconomyClass'].copy()\n","\n","    # Call the allocation function for each segment\n","    c2d=matching_s2d_flights\n","    c2d.reset_index(drop=True, inplace=True)\n","    DD=change_format(group_df.iloc[0][\"AT\"])\n","    for i in range(len(c2d)):\n","        t=change_format(c2d.loc[i][\"DepartureDateTime\"])\n","        if not is_within_n_days(DD,t,3) or c2d.loc[i][\"DepartureAirport\"].replace(\" \",\"\")!=group_df.iloc[0][\"AA\"].replace(\" \",\"\"):\n","             c2d=c2d.drop(i)\n","    # print(c2d.shape,\"@\")\n","    c2d=c2d.sort_values(by='DepartureDateTime')\n","    # print(c2d.shape)\n","    df_result = complete_allocation(df_FC, df_BC, df_PC, df_EC, c2d)\n","\n","    return df_result"],"metadata":{"id":"RGhAKbcltneN","executionInfo":{"status":"ok","timestamp":1702737283475,"user_tz":-330,"elapsed":3,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["combined_result_df = pd.DataFrame()"],"metadata":{"id":"pUUbPo8Stcen","executionInfo":{"status":"ok","timestamp":1702737283476,"user_tz":-330,"elapsed":3,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["for idx, group_df in enumerate(grouped_dfs):\n","    result_df = process_group(group_df, matching_s2d_flights)\n","    if(result_df.shape[0]==0):\n","        continue\n","    combined_result_df = pd.concat([result_df,combined_result_df], ignore_index=True)"],"metadata":{"id":"R2F5iQ-b49zK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Number Allocated in Second Journey**"],"metadata":{"id":"SOwJmksStyUx"}},{"cell_type":"code","source":["print(\"Number of Passenger Allocated = \",combined_result_df.shape[0])\n","passengers_not_scheduled = affect_sorted_PNR[~affect_sorted_PNR['RECLOC'].isin(combined_result_df['PNR'])]\n","print(\"Passenger not get Scheduled in second Journey =\",passengers_not_scheduled.shape[0])"],"metadata":{"id":"3v8hbcPM5VT3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Thus, we are taking into account that, even in the unlikely event that it is conceivable, passengers who are not scheduled for the connecting flight from the connecting airport to the destination will not receive any possible itinerary for the trip from the source to the connection.\n"],"metadata":{"id":"hF1dEWlAujq1"}},{"cell_type":"markdown","source":["**Storing 1st and 2nd Iternary of imapacted passenger**"],"metadata":{"id":"zVNjYs_ck2C0"}},{"cell_type":"code","source":["passengers_scheduled_j1 = dfn[dfn['PNR'].isin(combined_result_df['PNR'])]\n","passengers_scheduled_j1.to_csv(\"/content/Journey1.csv\",index=False)\n","combined_result_df.to_csv(\"/content/Journey2.csv\")"],"metadata":{"id":"WzQS9VFUk43F","executionInfo":{"status":"ok","timestamp":1702737307012,"user_tz":-330,"elapsed":467,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":["# **END**"],"metadata":{"id":"mLb_pTfjDW5w"}}]}