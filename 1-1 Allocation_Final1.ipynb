{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqkpqaVjaMQp2v3dUiUROT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASofYeboTh5H","executionInfo":{"status":"ok","timestamp":1702738557477,"user_tz":-330,"elapsed":6299,"user":{"displayName":"Team-69","userId":"15141329460336760271"}},"outputId":"a3b22ebb-c2af-4009-fcfb-1c28168f000a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import datetime"],"metadata":{"id":"OO5_WgIwTqxm","executionInfo":{"status":"ok","timestamp":1702738640211,"user_tz":-330,"elapsed":906,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading Block"],"metadata":{"id":"zSa4jw2cUm7l"}},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3824,"status":"ok","timestamp":1702738646256,"user":{"displayName":"Team-69","userId":"15141329460336760271"},"user_tz":-330},"id":"H2UY0lHjHLRj"},"outputs":[],"source":["df_pnr_book=pd.read_csv(\"/content/drive/MyDrive/TEAM-69/Final Dataset/PNRB-ZZ-20231208_062017.csv\")\n","df_pnr_pass=pd.read_csv('/content/drive/MyDrive/TEAM-69/Final Dataset/PNRP-ZZ-20231208_111136.csv')\n","df_schedule = pd.read_csv('/content/drive/MyDrive/TEAM-69/Final Dataset/SCH-ZZ-20231208_035117.csv')\n","df_inventory = pd.read_csv('/content/drive/MyDrive/TEAM-69/Final Dataset/INV-ZZ-20231208_041852.csv')"]},{"cell_type":"markdown","source":["# Data Preprocessing Block"],"metadata":{"id":"ZHGYXTIsUafZ"}},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6718,"status":"ok","timestamp":1702738652968,"user":{"displayName":"Team-69","userId":"15141329460336760271"},"user_tz":-330},"id":"zl2C64Lb5u_i"},"outputs":[],"source":["date_columns = ['DEP_DTML', 'ARR_DTML', 'DEP_DTMZ', 'ARR_DTMZ']\n","for column in date_columns:\n","    df_pnr_book[column] = pd.to_datetime(df_pnr_book[column], errors='coerce').dt.strftime('%m/%d/%Y %H:%M')\n","\n","df_pnr_book['DEP_DT'] = pd.to_datetime(df_pnr_book['DEP_DT'], errors='coerce').dt.strftime('%m/%d/%Y')\n","\n","\n","#For Inventory\n","\n","df_inventory['DepartureDate'] = pd.to_datetime(df_inventory['DepartureDate'], errors='coerce').dt.strftime('%m/%d/%Y')\n","date_columns = ['DepartureDateTime', 'ArrivalDateTime']\n","for column in date_columns:\n","    df_inventory[column] = pd.to_datetime(df_inventory[column], errors='coerce').dt.strftime('%Y/%m/%d %H:%M:%S')\n","\n","date_columns = ['DepartureDateTime', 'ArrivalDateTime']\n","df_inventory[date_columns] = df_inventory[date_columns].apply(pd.to_datetime, format='%Y-%m-%d %H:%M:%S')"]},{"cell_type":"code","source":["df_pnr_book_copy=df_pnr_book.copy()\n","df_pnr_book_copy1=df_pnr_book.copy()\n","df_pnr_pass_copy=df_pnr_pass.copy()\n","df_pnr_pass_copy1=df_pnr_pass.copy()\n","df_schedule_copy=df_schedule.copy()\n","df_schedule_copy1=df_schedule.copy()\n","df_inventory_copy=df_inventory.copy()\n","df_inventory_copy1=df_inventory.copy()"],"metadata":{"id":"ES2Lge71GwaQ","executionInfo":{"status":"ok","timestamp":1702738652969,"user_tz":-330,"elapsed":14,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Input Block"],"metadata":{"id":"BoNC90lfVdUP"}},{"cell_type":"markdown","source":["Example Input:\n","cancelled_FN = 2019,\n","cancelled_TN = 'VT-7102',\n","departure_date = '04/21/2024'"],"metadata":{"id":"bciSe-LyVjcf"}},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1702738652971,"user":{"displayName":"Team-69","userId":"15141329460336760271"},"user_tz":-330},"id":"QjIy2QLU5vDX"},"outputs":[],"source":["cancelled_FN = 2019\n","cancelled_TN = 'VT-7102'\n","departure_date = '04/21/2024'"]},{"cell_type":"code","source":["cancelled_FN = int(input(\"Enter the flight number: \"))\n","\n","# Taking user input for tail_number as a string\n","cancelled_TN= input(\"Enter the tail number: \")\n","\n","# Taking user input for date as a string\n","departure_date= input(\"Enter the date (MM/DD/YYYY): \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdR0nO37T7BF","executionInfo":{"status":"ok","timestamp":1702574414530,"user_tz":-330,"elapsed":17890,"user":{"displayName":"Team-69","userId":"15141329460336760271"}},"outputId":"f76cc43c-5e00-4ebc-c5e6-a5d32bc6878c"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter the flight number: 2019\n","Enter the tail number: VT-7102\n","Enter the date (MM/DD/YYYY): 04/21/2024\n"]}]},{"cell_type":"markdown","source":["# The 1-1 Reallocation Function Block(Prioritizing the classes of Passengers)"],"metadata":{"id":"XFOsyAYYWQFx"}},{"cell_type":"markdown","source":["Our goal is to prioritize the reaccommodation of passengers according to their classes, even if it requires making some adjustments to the accommodation based on the priority of flights."],"metadata":{"id":"6u6IgnF4UMWz"}},{"cell_type":"code","source":["def datframe_allocation(df_pnr_pass, df_pnr_book, df_schedule,df_inventory, cancelled_FN, cancelled_TN, departure_date):\n","    def get_available_flights_1_1(schedule_df, inventory_df, cancelled_FN, cancelled_TN, departure_date):\n","        cancelled_schedule = df_schedule[(df_schedule['AircraftTailNumber'] == cancelled_TN) & (df_schedule['FlightNumber'] == cancelled_FN)]\n","        print(cancelled_schedule['ScheduleID'].iloc[0])\n","\n","        cancelled_flight = df_inventory[(df_inventory['ScheduleId'] == cancelled_schedule['ScheduleID'].iloc[0]) & (df_inventory['DepartureDate'] == departure_date)]\n","        cancelled_flight_DepartureDateTime = cancelled_flight['DepartureDateTime'].iloc[0]\n","        cancelled_flight_ArrivalDateTime = cancelled_flight['ArrivalDateTime'].iloc[0]\n","\n","        matching_flights = df_inventory[\n","        (df_inventory['DepartureAirport'] == cancelled_flight['DepartureAirport'].iloc[0]) &\n","        (df_inventory['ArrivalAirport'] == cancelled_flight['ArrivalAirport'].iloc[0]) &\n","        (df_inventory['DepartureDateTime'] > cancelled_flight_DepartureDateTime)\n","        ]\n","\n","        columns_to_keep=['InventoryId', 'ScheduleId', 'CarrierCode', 'Dep_Key', 'FlightNumber', 'AircraftType', 'DepartureDate', 'DepartureDateTime', 'ArrivalDateTime', 'DepartureAirport', 'ArrivalAirport', 'TotalCapacity', 'TotalInventory','BookedInventory', 'Oversold', 'AvailableInventory', 'FirstClass', 'BusinessClass', 'PremiumEconomyClass', 'EconomyClass', 'FC_TotalInventory', 'FC_BookedInventory', 'FC_Oversold', 'FC_AvailableInventory', 'BC_TotalInventory', 'BC_BookedInventory', 'BC_Oversold', 'BC_AvailableInventory', 'PC_TotalInventory', 'PC_BookedInventory', 'PC_Oversold', 'PC_AvailableInventory', 'EC_TotalInventory', 'EC_BookedInventory', 'EC_Oversold', 'EC_AvailableInventory', 'FC_CD', 'BC_CD', 'PC_CD', 'EC_CD']\n","        matching_flights = matching_flights[columns_to_keep]\n","\n","        matching_flights['Arrival_TimeDifference'] = (matching_flights['ArrivalDateTime'] - cancelled_flight_ArrivalDateTime).dt.total_seconds()/3600\n","        matching_flights = matching_flights.sort_values(by='Arrival_TimeDifference')\n","        print(matching_flights.shape)\n","        return matching_flights\n","\n","    def process_pnr_data(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date):\n","        dept_time = df_schedule[(df_schedule['FlightNumber'] == flight_number) & (df_schedule['AircraftTailNumber'] == tail_number)]['DepartureTime'].iloc[0]\n","        date_time = date + ' ' + dept_time\n","        print(date_time)\n","\n","        def cal_affected_persons(flt_number, date_time):\n","            dict={}\n","            affect_persons = pd.DataFrame(columns=df_pnr_book.columns)\n","\n","            for i in range(len(df_pnr_book)):\n","                if df_pnr_book.loc[i, \"RECLOC\"] in dict.keys():\n","                    dict[df_pnr_book.loc[i, \"RECLOC\"]] = max(dict[df_pnr_book.loc[i, \"RECLOC\"]], df_pnr_book.loc[i, \"SEG_SEQ\"])\n","                else:\n","                    dict[df_pnr_book.loc[i, \"RECLOC\"]] = df_pnr_book.loc[i, \"SEG_SEQ\"]\n","\n","                if df_pnr_book.loc[i, \"FLT_NUM\"] == flt_number and df_pnr_book.loc[i, \"DEP_DTML\"] == date_time:\n","                    affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","            li = []\n","            for i in range(len(affect_persons)):\n","                if(dict[affect_persons.iloc[i][\"RECLOC\"]]):\n","                     li.append(dict[affect_persons.iloc[i][\"RECLOC\"]])\n","            affect_persons[\"MAX_SEG\"] = li\n","            return affect_persons\n","\n","        def calc_ssr(flight_number, date_time):\n","            affect_person = cal_affected_persons(flight_number, date_time)\n","            li = []\n","            for i in range(len(affect_person)):\n","                li.append(0)\n","            affect_person[\"count_ssr\"] = li\n","            for i in range(len(affect_person)):\n","                for j in range(len(df_pnr_pass)):\n","                    if df_pnr_pass.loc[j, \"RECLOC\"] == affect_person.iloc[i][\"RECLOC\"]:\n","                        if pd.notna(df_pnr_pass[\"SSR_CODE_CD1\"][j]) or pd.notna(df_pnr_pass[\"SPECIAL_NAME_CD2\"][j]):\n","                            affect_person.iloc[i][\"count_ssr\"] += 1\n","            return affect_person\n","\n","        def score_eval(affect_PNR):\n","            score = 0\n","            score += 200 * affect_PNR.loc[\"count_ssr\"] + 50 * affect_PNR.loc[\"PAX_CNT\"]\n","            score += 100 * (affect_PNR.loc[\"MAX_SEG\"] - affect_PNR.loc[\"SEG_SEQ\"])\n","            score_dict = {'A': 'J', 'D': 'J', 'J': 'J', 'B': 'F', 'F': 'F', 'S': 'Y', 'V': 'Y', 'W': 'Y', 'Z': 'Y', 'O': 'Y',\n","                      'S': 'Y', 'T': 'Y', 'U': 'Y', 'M': 'Y', 'N': 'Y', 'Y': 'Y'}\n","            if affect_PNR.loc[\"COS_CD\"] not in score_dict.keys():\n","                score += 500\n","            elif affect_PNR.loc[\"COS_CD\"] == 'J' or score_dict[affect_PNR.loc[\"COS_CD\"]] == 'J':\n","                score += 2000\n","            elif affect_PNR.loc[\"COS_CD\"] == \"F\" or score_dict[affect_PNR.loc[\"COS_CD\"]] == \"F\":\n","                score += 1700\n","            elif affect_PNR.loc[\"COS_CD\"] == \"Y\" or score_dict[affect_PNR.loc[\"COS_CD\"]] == \"Y\":\n","                score += 1500\n","            elif affect_PNR.loc[\"COS_CD\"] in [\"A\", \"C\", \"K\"]:\n","                score += 800\n","            return score\n","\n","        def score(flight, data_time):\n","            affect_PNR = calc_ssr(flight, data_time)\n","            pnr_ranking = pd.DataFrame(columns=affect_PNR.columns.tolist() + ['score'])\n","            for i in range(len(affect_PNR)):\n","                score_val = score_eval(affect_PNR.iloc[i])\n","                affect_row = list(affect_PNR.iloc[i])\n","                affect_row.append(score_val)\n","                pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","\n","            sorted_pnr_ranking = pnr_ranking.sort_values(by='score', ascending=False)\n","            return sorted_pnr_ranking\n","        return score(flight_number, date_time)\n","\n","    def get_ITN_DEST(df):\n","        df[['SEG_SEQ', 'SEG_TOTAL']] = df[['SEG_SEQ', 'SEG_TOTAL']].apply(pd.to_numeric, errors='coerce')\n","        max_dest_per_recloc = df.loc[df['SEG_SEQ'] == df['SEG_TOTAL']].groupby('RECLOC')['DEST_CD'].first().reset_index()\n","        df = pd.merge(df, max_dest_per_recloc, on='RECLOC', how='left', suffixes=('', '_ITN_DEST'))\n","        return df\n","    def get_cluster_rank(affect_sorted_PNR):\n","        cluster_means = affect_sorted_PNR.groupby('DEST_CD_ITN_DEST')['score'].mean()\n","        rank_mapping = {cluster: rank for rank, (cluster, _) in enumerate(cluster_means.sort_values(ascending=False).iteritems(), start=1)}\n","        affect_sorted_PNR['CLUSTER_RANK'] = affect_sorted_PNR['DEST_CD_ITN_DEST'].map(rank_mapping)\n","        return affect_sorted_PNR\n","\n","    def get_pnr_affected(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date):\n","        df_pnr_book = get_ITN_DEST(df_pnr_book)\n","        affect_sorted_PNR = process_pnr_data(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date)\n","        final_affected_PNR = get_cluster_rank(affect_sorted_PNR)\n","        return final_affected_PNR\n","    def knapsack1(left_seats, n, li, PNR_df, memo):\n","        if n == 0 or left_seats == 0:\n","            return left_seats, li\n","\n","    # Check if the result is already memoized\n","        if (left_seats, n) in memo:\n","             return memo[(left_seats, n)]\n","\n","        if left_seats >= PNR_df.iloc[n-1][\"PAX_CNT\"]:\n","        # Recursively compute the result and memoize it\n","            result1 = knapsack1(left_seats, n-1, li, PNR_df, memo)\n","            result2 = knapsack1(left_seats - PNR_df.iloc[n-1][\"PAX_CNT\"], n-1, li + [PNR_df.iloc[n-1][\"RECLOC\"]], PNR_df, memo)\n","            result = min(result1, result2, key=lambda x: x[0])\n","        else:\n","            result = knapsack1(left_seats, n-1, li, PNR_df, memo)\n","\n","    # Memoize the result\n","        memo[(left_seats, n)] = result\n","\n","        return result\n","\n","    # Example usag  # Replace with your actual DataFrame\n","\n","    def delete_entry(to_delete, dataframe):\n","        # print(dataframe)\n","        for i in to_delete:\n","            dataframe.drop(dataframe[dataframe[\"RECLOC\"]==i].index, inplace=True, axis=0)\n","        return dataframe\n","\n","    def all_flights_knapsack_for_same_class1(df_PNR, flights, cls):\n","        prev_cls=cls\n","        allocated_dict = {}\n","        for i in range(len(flights)):\n","            seats_left, allocated_PNRs = knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR, {})\n","\n","        # Update the values in the flights DataFrame\n","            temp_column = cls+\"_AvailableInventory\"\n","            temp = flights.iloc[i][temp_column]\n","            column_index = flights.columns.get_loc(temp_column)\n","            flights.iat[i, column_index] = seats_left\n","            flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","            df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","            allocated_dict[flights.iloc[i][\"InventoryId\"]] = [(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","        return allocated_dict\n","\n","    def merge_dict(dict1,dict2):\n","        list1=dict1.keys()\n","        for i in list1:\n","            dict1[i]=dict1[i]+dict2[i]\n","        return dict1\n","\n","    def convert_dict_to_dataframe(allocated_dict):\n","        data = []\n","        for inventory_id, allocations in allocated_dict.items():\n","            for allocation in allocations:\n","                pnr, class_name,prev_clssname = allocation\n","                data.append({'PNR': pnr, 'InventoryId': inventory_id, 'New_ClassName': class_name,'Prev_ClassName': prev_clssname})\n","\n","        df = pd.DataFrame(data)\n","        return df\n","\n","    def complete_allocation(df_FC_copy,df_BC_copy,df_PE_copy,df_EC_copy,flights):\n","        # FC_allocation={}\n","        # BC_allocation={}\n","        # PE_allocation={}\n","        # EC_allocation={}\n","        FC_allocation=all_flights_knapsack_for_same_class1(df_FC_copy, flights, \"FC\")\n","        BC_allocation=all_flights_knapsack_for_same_class1(df_BC_copy, flights, \"BC\")\n","        PE_allocation=all_flights_knapsack_for_same_class1(df_PE_copy, flights, \"PC\")\n","        EC_allocation=all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"EC\")\n","        # print(FC_allocation)\n","        # print(BC_allocation)\n","        print(PE_allocation)\n","        # print(EC_allocation)\n","\n","\n","        if not df_FC_copy.empty:\n","            PE_allocation.update(all_flights_knapsack_for_same_class1(df_FC_copy, flights, \"PC\"))\n","            EC_allocation.update(all_flights_knapsack_for_same_class1(df_FC_copy, flights, \"EC\"))\n","        if not df_BC_copy.COS_CD.empty:\n","            EC_allocation.update(all_flights_knapsack_for_same_class1(df_BC_copy, flights, \"EC\"))\n","        if not df_PE_copy.empty:\n","            FC_allocation.update(all_flights_knapsack_for_same_class1(df_PE_copy, flights, \"FC\"))\n","        if not df_EC_copy.empty:\n","            FC_allocation.update(all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"FC\"))\n","            BC_allocation.update(all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"BC\"))\n","            PE_allocation.update(all_flights_knapsack_for_same_class1(df_EC_copy, flights, \"PC\"))\n","\n","        # return  FC_allocation,BC_allocation,PE_allocation,EC_allocation\n","        df=convert_dict_to_dataframe(FC_allocation)\n","        df=pd.concat([df, convert_dict_to_dataframe(BC_allocation)], ignore_index=True)\n","        df=pd.concat([df, convert_dict_to_dataframe(PE_allocation)], ignore_index=True)\n","        df=pd.concat([df, convert_dict_to_dataframe(EC_allocation)], ignore_index=True)\n","        PNR_NOT_Allocated=df_FC_copy['RECLOC'].tolist()\n","        PNR_NOT_Allocated=PNR_NOT_Allocated+df_BC_copy['RECLOC'].tolist()+df_PE_copy['RECLOC'].tolist()+df_EC_copy['RECLOC'].tolist()\n","        new_df=pd.DataFrame({'PNR':PNR_NOT_Allocated})\n","        print(df)\n","        result_df = pd.merge(df, new_df, on='PNR', how='left')\n","        # result_df[['InventoryID','New_ClassName','Prev_ClassName']] = df[['InventoryID','New_ClassName','Prev_ClassName']]\n","        merged_df = pd.merge(df, flights, on='InventoryId', how='inner')\n","        result_df= new_df.set_index('PNR').combine_first(merged_df.set_index('PNR')).reset_index()\n","        return result_df\n","\n","    def classification(affect_sorted_PNR):\n","        # Assuming 'affect_sorted_PNR' is your DataFram\n","        df_FC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'FirstClass'].copy()\n","        df_BC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'BusinessClass'].copy()\n","        df_PC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'PremiumEconomyClass'].copy()\n","        df_EC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'EconomyClass'].copy()\n","        return df_FC,df_BC,df_PC,df_EC\n","\n","\n","    matching_flights=get_available_flights_1_1(df_schedule, df_inventory, cancelled_FN, cancelled_TN, departure_date)\n","    affect_sorted_PNR = get_pnr_affected(df_pnr_pass, df_pnr_book, df_schedule, cancelled_FN, cancelled_TN, departure_date)\n","    df_FC,df_BC,df_PC,df_EC=classification(affect_sorted_PNR)\n","\n","    df=complete_allocation(df_FC,df_BC,df_PC,df_EC,matching_flights)\n","\n","    return df,len(affect_sorted_PNR)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"aD7QByrjV5Dh","executionInfo":{"status":"ok","timestamp":1702738754595,"user_tz":-330,"elapsed":633,"user":{"displayName":"Team-69","userId":"15141329460336760271"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Result Block"],"metadata":{"id":"xh8_G_wKWrR0"}},{"cell_type":"markdown","source":["Just run and wait for the output CSV to be generated"],"metadata":{"id":"oezvU-OwTVWm"}},{"cell_type":"code","source":["df,number_of_affected_PNRs=datframe_allocation(df_pnr_pass_copy, df_pnr_book_copy, df_schedule_copy,df_inventory_copy, cancelled_FN, cancelled_TN, departure_date)\n","df.to_csv('1-1 Reallocation_Class_Priority.csv', index=False)"],"metadata":{"id":"V83EhndiWgcJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hcgFfhFEYYl2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The 1-1 Allocation (Prioritizing the Flights)"],"metadata":{"id":"9q_TTgO2Ygcu"}},{"cell_type":"markdown","source":["We aim to prioritize reaccommodating passengers on the most essential flights, even if it means making some adjustments to the accommodation based on class."],"metadata":{"id":"YR2fnQjqTB85"}},{"cell_type":"markdown","source":["# The 1-1 Reallocation Function Block(Prioritizing the flights of Passengers)"],"metadata":{"id":"5dhofGRaZINv"}},{"cell_type":"code","source":["def datframe_allocation1(df_pnr_pass, df_pnr_book, df_schedule,df_inventory, cancelled_FN, cancelled_TN, departure_date):\n","    def get_available_flights_1_1(schedule_df, inventory_df, cancelled_FN, cancelled_TN, departure_date):\n","        cancelled_schedule = df_schedule[(df_schedule['AircraftTailNumber'] == cancelled_TN) & (df_schedule['FlightNumber'] == cancelled_FN)]\n","        print(cancelled_schedule['ScheduleID'].iloc[0])\n","\n","        cancelled_flight = df_inventory[(df_inventory['ScheduleId'] == cancelled_schedule['ScheduleID'].iloc[0]) & (df_inventory['DepartureDate'] == departure_date)]\n","        cancelled_flight_DepartureDateTime = cancelled_flight['DepartureDateTime'].iloc[0]\n","        cancelled_flight_ArrivalDateTime = cancelled_flight['ArrivalDateTime'].iloc[0]\n","\n","        matching_flights = df_inventory[\n","        (df_inventory['DepartureAirport'] == cancelled_flight['DepartureAirport'].iloc[0]) &\n","        (df_inventory['ArrivalAirport'] == cancelled_flight['ArrivalAirport'].iloc[0]) &\n","        (df_inventory['DepartureDateTime'] > cancelled_flight_DepartureDateTime)\n","        ]\n","\n","        columns_to_keep=['InventoryId', 'ScheduleId', 'CarrierCode', 'Dep_Key', 'FlightNumber', 'AircraftType', 'DepartureDate', 'DepartureDateTime', 'ArrivalDateTime', 'DepartureAirport', 'ArrivalAirport', 'TotalCapacity', 'TotalInventory','BookedInventory', 'Oversold', 'AvailableInventory', 'FirstClass', 'BusinessClass', 'PremiumEconomyClass', 'EconomyClass', 'FC_TotalInventory', 'FC_BookedInventory', 'FC_Oversold', 'FC_AvailableInventory', 'BC_TotalInventory', 'BC_BookedInventory', 'BC_Oversold', 'BC_AvailableInventory', 'PC_TotalInventory', 'PC_BookedInventory', 'PC_Oversold', 'PC_AvailableInventory', 'EC_TotalInventory', 'EC_BookedInventory', 'EC_Oversold', 'EC_AvailableInventory', 'FC_CD', 'BC_CD', 'PC_CD', 'EC_CD']\n","        matching_flights = matching_flights[columns_to_keep]\n","\n","        matching_flights['Arrival_TimeDifference'] = (matching_flights['ArrivalDateTime'] - cancelled_flight_ArrivalDateTime).dt.total_seconds()/3600\n","        matching_flights = matching_flights.sort_values(by='Arrival_TimeDifference')\n","        print(matching_flights.shape)\n","        return matching_flights\n","\n","    def process_pnr_data(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date):\n","        dept_time = df_schedule[(df_schedule['FlightNumber'] == flight_number) & (df_schedule['AircraftTailNumber'] == tail_number)]['DepartureTime'].iloc[0]\n","        date_time = date + ' ' + dept_time\n","        print(date_time)\n","\n","        def cal_affected_persons(flt_number, date_time):\n","            dict={}\n","            affect_persons = pd.DataFrame(columns=df_pnr_book.columns)\n","\n","            for i in range(len(df_pnr_book)):\n","                if df_pnr_book.loc[i, \"RECLOC\"] in dict.keys():\n","                    dict[df_pnr_book.loc[i, \"RECLOC\"]] = max(dict[df_pnr_book.loc[i, \"RECLOC\"]], df_pnr_book.loc[i, \"SEG_SEQ\"])\n","                else:\n","                    dict[df_pnr_book.loc[i, \"RECLOC\"]] = df_pnr_book.loc[i, \"SEG_SEQ\"]\n","\n","                if df_pnr_book.loc[i, \"FLT_NUM\"] == flt_number and df_pnr_book.loc[i, \"DEP_DTML\"] == date_time:\n","                    affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","            li = []\n","            for i in range(len(affect_persons)):\n","                if(dict[affect_persons.iloc[i][\"RECLOC\"]]):\n","                     li.append(dict[affect_persons.iloc[i][\"RECLOC\"]])\n","            affect_persons[\"MAX_SEG\"] = li\n","            return affect_persons\n","\n","        def calc_ssr(flight_number, date_time):\n","            affect_person = cal_affected_persons(flight_number, date_time)\n","            li = []\n","            for i in range(len(affect_person)):\n","                li.append(0)\n","            affect_person[\"count_ssr\"] = li\n","            for i in range(len(affect_person)):\n","                for j in range(len(df_pnr_pass)):\n","                    if df_pnr_pass.loc[j, \"RECLOC\"] == affect_person.iloc[i][\"RECLOC\"]:\n","                        if pd.notna(df_pnr_pass[\"SSR_CODE_CD1\"][j]) or pd.notna(df_pnr_pass[\"SPECIAL_NAME_CD2\"][j]):\n","                            affect_person.iloc[i][\"count_ssr\"] += 1\n","            return affect_person\n","\n","        def score_eval(affect_PNR):\n","            score = 0\n","            score += 200 * affect_PNR.loc[\"count_ssr\"] + 50 * affect_PNR.loc[\"PAX_CNT\"]\n","            score += 100 * (affect_PNR.loc[\"MAX_SEG\"] - affect_PNR.loc[\"SEG_SEQ\"])\n","            score_dict = {'A': 'J', 'D': 'J', 'J': 'J', 'B': 'F', 'F': 'F', 'S': 'Y', 'V': 'Y', 'W': 'Y', 'Z': 'Y', 'O': 'Y',\n","                      'S': 'Y', 'T': 'Y', 'U': 'Y', 'M': 'Y', 'N': 'Y', 'Y': 'Y'}\n","            if affect_PNR.loc[\"COS_CD\"] not in score_dict.keys():\n","                score += 500\n","            elif affect_PNR.loc[\"COS_CD\"] == 'J' or score_dict[affect_PNR.loc[\"COS_CD\"]] == 'J':\n","                score += 2000\n","            elif affect_PNR.loc[\"COS_CD\"] == \"F\" or score_dict[affect_PNR.loc[\"COS_CD\"]] == \"F\":\n","                score += 1700\n","            elif affect_PNR.loc[\"COS_CD\"] == \"Y\" or score_dict[affect_PNR.loc[\"COS_CD\"]] == \"Y\":\n","                score += 1500\n","            elif affect_PNR.loc[\"COS_CD\"] in [\"A\", \"C\", \"K\"]:\n","                score += 800\n","            return score\n","\n","        def score(flight, data_time):\n","            affect_PNR = calc_ssr(flight, data_time)\n","            pnr_ranking = pd.DataFrame(columns=affect_PNR.columns.tolist() + ['score'])\n","            for i in range(len(affect_PNR)):\n","                score_val = score_eval(affect_PNR.iloc[i])\n","                affect_row = list(affect_PNR.iloc[i])\n","                affect_row.append(score_val)\n","                pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","\n","            sorted_pnr_ranking = pnr_ranking.sort_values(by='score', ascending=False)\n","            return sorted_pnr_ranking\n","        return score(flight_number, date_time)\n","\n","    def get_ITN_DEST(df):\n","        df[['SEG_SEQ', 'SEG_TOTAL']] = df[['SEG_SEQ', 'SEG_TOTAL']].apply(pd.to_numeric, errors='coerce')\n","        max_dest_per_recloc = df.loc[df['SEG_SEQ'] == df['SEG_TOTAL']].groupby('RECLOC')['DEST_CD'].first().reset_index()\n","        df = pd.merge(df, max_dest_per_recloc, on='RECLOC', how='left', suffixes=('', '_ITN_DEST'))\n","        return df\n","    def get_cluster_rank(affect_sorted_PNR):\n","        cluster_means = affect_sorted_PNR.groupby('DEST_CD_ITN_DEST')['score'].mean()\n","        rank_mapping = {cluster: rank for rank, (cluster, _) in enumerate(cluster_means.sort_values(ascending=False).iteritems(), start=1)}\n","        affect_sorted_PNR['CLUSTER_RANK'] = affect_sorted_PNR['DEST_CD_ITN_DEST'].map(rank_mapping)\n","        return affect_sorted_PNR\n","\n","    def get_pnr_affected(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date):\n","        df_pnr_book = get_ITN_DEST(df_pnr_book)\n","        affect_sorted_PNR = process_pnr_data(df_pnr_pass, df_pnr_book, df_schedule, flight_number, tail_number, date)\n","        final_affected_PNR = get_cluster_rank(affect_sorted_PNR)\n","        return final_affected_PNR\n","    def knapsack1(left_seats, n, li, PNR_df, memo):\n","        if n == 0 or left_seats == 0:\n","            return left_seats, li\n","\n","    # Check if the result is already memoized\n","        if (left_seats, n) in memo:\n","             return memo[(left_seats, n)]\n","\n","        if left_seats >= PNR_df.iloc[n-1][\"PAX_CNT\"]:\n","        # Recursively compute the result and memoize it\n","            result1 = knapsack1(left_seats, n-1, li, PNR_df, memo)\n","            result2 = knapsack1(left_seats - PNR_df.iloc[n-1][\"PAX_CNT\"], n-1, li + [PNR_df.iloc[n-1][\"RECLOC\"]], PNR_df, memo)\n","            result = min(result1, result2, key=lambda x: x[0])\n","        else:\n","            result = knapsack1(left_seats, n-1, li, PNR_df, memo)\n","\n","    # Memoize the result\n","        memo[(left_seats, n)] = result\n","\n","        return result\n","\n","    # Example usag  # Replace with your actual DataFrame\n","\n","    def delete_entry(to_delete, dataframe):\n","        # print(dataframe)\n","        for i in to_delete:\n","            dataframe.drop(dataframe[dataframe[\"RECLOC\"]==i].index, inplace=True, axis=0)\n","        return dataframe\n","\n","    def partial_allocation_knapsack1(df_PNR,flights,cls):\n","        allocated_dict={}\n","        prev_cls=cls\n","        for i in range(len(flights)):\n","           seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","\n","           temp_column = cls+\"_AvailableInventory\"\n","           temp = flights.iloc[i][temp_column]\n","           column_index = flights.columns.get_loc(temp_column)\n","           flights.iat[i, column_index] = seats_left\n","           flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","           df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","           allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","\n","           if(not df_PNR.empty):\n","            if(cls=='FC'):\n","                # prev_cls=cls\n","                cls='BC'\n","                seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                temp_column = cls+\"_AvailableInventory\"\n","                temp = flights.iloc[i][temp_column]\n","                column_index = flights.columns.get_loc(temp_column)\n","                flights.iat[i, column_index] = seats_left\n","                flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","                if(not df_PNR.empty):\n","                    cls='PC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","                if(not df_PNR.empty):\n","                    cls='EC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","            elif(cls=='BC'):\n","                # prev_cls=cls\n","                cls='PC'\n","                seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                temp_column = cls+\"_AvailableInventory\"\n","                temp = flights.iloc[i][temp_column]\n","                column_index = flights.columns.get_loc(temp_column)\n","                flights.iat[i, column_index] = seats_left\n","                flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","                if(not df_PNR.empty):\n","                    cls='EC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","                if(not df_PNR.empty):\n","                    cls='FC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","            elif(cls=='PC'):\n","                # prev_cls=cls\n","                cls='EC'\n","                seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                temp_column = cls+\"_AvailableInventory\"\n","                temp = flights.iloc[i][temp_column]\n","                column_index = flights.columns.get_loc(temp_column)\n","                flights.iat[i, column_index] = seats_left\n","                flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","                if(not df_PNR.empty):\n","                    cls='BC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","                if(not df_PNR.empty):\n","                    cls='FC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","            elif(cls=='EC' ):\n","                # prev_cls=cls\n","                cls='PC'\n","                seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                temp_column = cls+\"_AvailableInventory\"\n","                temp = flights.iloc[i][temp_column]\n","                column_index = flights.columns.get_loc(temp_column)\n","                flights.iat[i, column_index] = seats_left\n","                flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","                if(not df_PNR.empty):\n","                    cls='BC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","                if(not df_PNR.empty):\n","                    cls='FC'\n","                    seats_left,allocated_PNRs=knapsack1(flights.iloc[i][cls+\"_AvailableInventory\"], len(df_PNR), [], df_PNR,{})\n","                    temp_column = cls+\"_AvailableInventory\"\n","                    temp = flights.iloc[i][temp_column]\n","                    column_index = flights.columns.get_loc(temp_column)\n","                    flights.iat[i, column_index] = seats_left\n","                    flights.iat[i, flights.columns.get_loc(\"AvailableInventory\")] -= temp - seats_left\n","                    df_PNR = delete_entry(allocated_PNRs, df_PNR)\n","                    allocated_dict[flights.iloc[i][\"InventoryId\"]] = allocated_dict.get(flights.iloc[i][\"InventoryId\"], [])+[(pnr, cls,prev_cls) for pnr in allocated_PNRs]\n","\n","        return allocated_dict\n","\n","\n","\n","\n","\n","\n","\n","\n","    def merge_dict(dict1,dict2):\n","        list1=dict1.keys()\n","        for i in list1:\n","            dict1[i]=dict1[i]+dict2[i]\n","        return dict1\n","\n","    def convert_dict_to_dataframe(allocated_dict):\n","        data = []\n","        for inventory_id, allocations in allocated_dict.items():\n","            for allocation in allocations:\n","                pnr, class_name,prev_clssname = allocation\n","                data.append({'PNR': pnr, 'InventoryId': inventory_id, 'New_ClassName': class_name,'Prev_ClassName': prev_clssname})\n","\n","        df = pd.DataFrame(data)\n","        return df\n","\n","    def the_alloactions(df_FC_copy,df_BC_copy,df_PE_copy,df_EC_copy,flights):\n","        partial_FC_alloaction=partial_allocation_knapsack1(df_FC_copy, flights, \"FC\")\n","        partial_BC_alloaction=partial_allocation_knapsack1(df_BC_copy, flights, \"BC\")\n","        partial_PE_alloaction=partial_allocation_knapsack1(df_PE_copy, flights, \"PC\")\n","        partial_EC_alloaction=partial_allocation_knapsack1(df_EC_copy, flights, \"EC\")\n","        PNR_NOT_Allocated=df_FC_copy['RECLOC'].tolist()\n","        PNR_NOT_Allocated=PNR_NOT_Allocated+df_BC_copy['RECLOC'].tolist()+df_PE_copy['RECLOC'].tolist()+df_EC_copy['RECLOC'].tolist()\n","\n","        df=convert_dict_to_dataframe(partial_FC_alloaction)\n","        df=pd.concat([df, convert_dict_to_dataframe(partial_BC_alloaction)], ignore_index=True)\n","        df=pd.concat([df, convert_dict_to_dataframe(partial_PE_alloaction)], ignore_index=True)\n","        df=pd.concat([df, convert_dict_to_dataframe(partial_EC_alloaction)], ignore_index=True)\n","        new_df=pd.DataFrame({'PNR':PNR_NOT_Allocated})\n","\n","        print(df)\n","\n","        print(flights)\n","\n","        merged_df = pd.merge(df, flights, on='InventoryId', how='inner')\n","\n","        result_df= new_df.set_index('PNR').combine_first(merged_df.set_index('PNR')).reset_index()\n","\n","\n","        return result_df\n","\n","\n","    def classification(affect_sorted_PNR):\n","        # Assuming 'affect_sorted_PNR' is your DataFram\n","        df_FC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'FirstClass'].copy()\n","        df_BC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'BusinessClass'].copy()\n","        df_PC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'PremiumEconomyClass'].copy()\n","        df_EC = affect_sorted_PNR[affect_sorted_PNR['COS_CD'] == 'EconomyClass'].copy()\n","        return df_FC,df_BC,df_PC,df_EC\n","\n","\n","    matching_flights=get_available_flights_1_1(df_schedule, df_inventory, cancelled_FN, cancelled_TN, departure_date)\n","    affect_sorted_PNR = get_pnr_affected(df_pnr_pass, df_pnr_book, df_schedule, cancelled_FN, cancelled_TN, departure_date)\n","    df_FC,df_BC,df_PC,df_EC=classification(affect_sorted_PNR)\n","\n","    df=the_alloactions(df_FC,df_BC,df_PC,df_EC,matching_flights)\n","\n","    return df,len(affect_sorted_PNR)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ffH7lHFaZTl4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Just run and wait for the output CSV to be generated"],"metadata":{"id":"IyeGvL2-Te-q"}},{"cell_type":"code","source":["df1,number_of_affected_PNRs=datframe_allocation1(df_pnr_pass_copy1, df_pnr_book_copy1, df_schedule_copy1,df_inventory_copy1, cancelled_FN, cancelled_TN, departure_date)\n","df1.to_csv('1-1 Reallocation_Flight_Priority.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwy6MJQHbptb","executionInfo":{"status":"ok","timestamp":1702632489565,"user_tz":-330,"elapsed":613660,"user":{"displayName":"Team-69","userId":"15141329460336760271"}},"outputId":"a57cce75-cde3-4f58-f05a-df42019b2473"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SCH-ZZ-1589980\n","(49, 41)\n","04/21/2024 16:42\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  affect_persons = affect_persons.append(df_pnr_book.loc[i])\n","<ipython-input-11-7a3e7a58bdc8>:58: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  affect_person.iloc[i][\"count_ssr\"] += 1\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  pnr_ranking = pnr_ranking.append(pd.Series(affect_row, index=pnr_ranking.columns), ignore_index=True)\n","<ipython-input-11-7a3e7a58bdc8>:99: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n","  rank_mapping = {cluster: rank for rank, (cluster, _) in enumerate(cluster_means.sort_values(ascending=False).iteritems(), start=1)}\n"]},{"output_type":"stream","name":"stdout","text":["       PNR     InventoryId New_ClassName Prev_ClassName\n","0   EXXS33  INV-ZZ-1957001            FC             FC\n","1   ELBU85  INV-ZZ-1957001            BC             FC\n","2   NHIY83  INV-ZZ-1957001            BC             FC\n","3   HYTZ86  INV-ZZ-1957001            BC             FC\n","4   CWTV97  INV-ZZ-1957001            BC             FC\n","5   RHLA51  INV-ZZ-1957001            PC             BC\n","6   HJCQ26  INV-ZZ-1957001            PC             BC\n","7   LFJE82  INV-ZZ-1957001            PC             BC\n","8   QPXJ84  INV-ZZ-1957001            EC             BC\n","9   ZGRB68  INV-ZZ-1957001            EC             BC\n","10  SXGH40  INV-ZZ-1957001            EC             BC\n","11  IWRM28  INV-ZZ-1957001            EC             BC\n","12  XLES89  INV-ZZ-1957001            EC             BC\n","13  MPCS79  INV-ZZ-1957001            EC             BC\n","14  TIKK22  INV-ZZ-1957001            EC             PC\n","15  WXXO13  INV-ZZ-1957001            EC             PC\n","16  VJIH63  INV-ZZ-4434695            FC             PC\n","17  NJUG57  INV-ZZ-4434695            BC             PC\n","18  KJQS58  INV-ZZ-4434695            BC             PC\n","19  ZEOJ18  INV-ZZ-4434695            PC             PC\n","20  OJJD32  INV-ZZ-4434695            PC             PC\n","21  HYFY52  INV-ZZ-1957001            EC             EC\n","22  GMAA16  INV-ZZ-4434695            PC             EC\n","23  ZKOV20  INV-ZZ-4434695            PC             EC\n","24  QKYX61  INV-ZZ-4434695            PC             EC\n","25  NYQT79  INV-ZZ-4434695            EC             EC\n","26  STKN67  INV-ZZ-4434695            EC             EC\n","27  SXCZ87  INV-ZZ-4434695            EC             EC\n","28  OCCI26  INV-ZZ-4434695            EC             EC\n","29  OKYE96  INV-ZZ-4434695            EC             EC\n","30  NWLA23  INV-ZZ-4434695            EC             EC\n","31  PMJJ15  INV-ZZ-4434695            EC             EC\n","         InventoryId      ScheduleId CarrierCode                 Dep_Key  \\\n","1060  INV-ZZ-1957001  SCH-ZZ-6544056          ZZ  ZZ20240422BOMDEL3869.0   \n","789   INV-ZZ-4434695  SCH-ZZ-1589980          ZZ  ZZ20240422BOMDEL2019.0   \n","790   INV-ZZ-3384707  SCH-ZZ-1589980          ZZ  ZZ20240424BOMDEL2019.0   \n","791   INV-ZZ-5961863  SCH-ZZ-1589980          ZZ  ZZ20240425BOMDEL2019.0   \n","792   INV-ZZ-8076299  SCH-ZZ-1589980          ZZ  ZZ20240426BOMDEL2019.0   \n","1061  INV-ZZ-1660465  SCH-ZZ-6544056          ZZ  ZZ20240427BOMDEL3869.0   \n","793   INV-ZZ-9771525  SCH-ZZ-1589980          ZZ  ZZ20240427BOMDEL2019.0   \n","794   INV-ZZ-1548562  SCH-ZZ-1589980          ZZ  ZZ20240428BOMDEL2019.0   \n","1062  INV-ZZ-3315702  SCH-ZZ-6544056          ZZ  ZZ20240429BOMDEL3869.0   \n","795   INV-ZZ-4216782  SCH-ZZ-1589980          ZZ  ZZ20240429BOMDEL2019.0   \n","796   INV-ZZ-7210908  SCH-ZZ-1589980          ZZ  ZZ20240501BOMDEL2019.0   \n","797   INV-ZZ-6845331  SCH-ZZ-1589980          ZZ  ZZ20240502BOMDEL2019.0   \n","798   INV-ZZ-7625532  SCH-ZZ-1589980          ZZ  ZZ20240503BOMDEL2019.0   \n","1063  INV-ZZ-1000517  SCH-ZZ-6544056          ZZ  ZZ20240504BOMDEL3869.0   \n","799   INV-ZZ-7490389  SCH-ZZ-1589980          ZZ  ZZ20240504BOMDEL2019.0   \n","800   INV-ZZ-8292072  SCH-ZZ-1589980          ZZ  ZZ20240505BOMDEL2019.0   \n","1064  INV-ZZ-5235833  SCH-ZZ-6544056          ZZ  ZZ20240506BOMDEL3869.0   \n","801   INV-ZZ-8427920  SCH-ZZ-1589980          ZZ  ZZ20240506BOMDEL2019.0   \n","802   INV-ZZ-2080355  SCH-ZZ-1589980          ZZ  ZZ20240508BOMDEL2019.0   \n","803   INV-ZZ-9384535  SCH-ZZ-1589980          ZZ  ZZ20240509BOMDEL2019.0   \n","804   INV-ZZ-5468464  SCH-ZZ-1589980          ZZ  ZZ20240510BOMDEL2019.0   \n","1065  INV-ZZ-8531232  SCH-ZZ-6544056          ZZ  ZZ20240511BOMDEL3869.0   \n","805   INV-ZZ-9681635  SCH-ZZ-1589980          ZZ  ZZ20240511BOMDEL2019.0   \n","806   INV-ZZ-8438601  SCH-ZZ-1589980          ZZ  ZZ20240512BOMDEL2019.0   \n","1066  INV-ZZ-5211947  SCH-ZZ-6544056          ZZ  ZZ20240513BOMDEL3869.0   \n","807   INV-ZZ-6222020  SCH-ZZ-1589980          ZZ  ZZ20240513BOMDEL2019.0   \n","808   INV-ZZ-2386817  SCH-ZZ-1589980          ZZ  ZZ20240515BOMDEL2019.0   \n","809   INV-ZZ-1931604  SCH-ZZ-1589980          ZZ  ZZ20240516BOMDEL2019.0   \n","810   INV-ZZ-3316277  SCH-ZZ-1589980          ZZ  ZZ20240517BOMDEL2019.0   \n","1067  INV-ZZ-4607728  SCH-ZZ-6544056          ZZ  ZZ20240518BOMDEL3869.0   \n","811   INV-ZZ-1672911  SCH-ZZ-1589980          ZZ  ZZ20240518BOMDEL2019.0   \n","812   INV-ZZ-1816914  SCH-ZZ-1589980          ZZ  ZZ20240519BOMDEL2019.0   \n","1068  INV-ZZ-9723853  SCH-ZZ-6544056          ZZ  ZZ20240520BOMDEL3869.0   \n","813   INV-ZZ-1533160  SCH-ZZ-1589980          ZZ  ZZ20240520BOMDEL2019.0   \n","814   INV-ZZ-6359165  SCH-ZZ-1589980          ZZ  ZZ20240522BOMDEL2019.0   \n","815   INV-ZZ-8223337  SCH-ZZ-1589980          ZZ  ZZ20240523BOMDEL2019.0   \n","816   INV-ZZ-3645468  SCH-ZZ-1589980          ZZ  ZZ20240524BOMDEL2019.0   \n","1069  INV-ZZ-3797226  SCH-ZZ-6544056          ZZ  ZZ20240525BOMDEL3869.0   \n","817   INV-ZZ-3898720  SCH-ZZ-1589980          ZZ  ZZ20240525BOMDEL2019.0   \n","818   INV-ZZ-7141721  SCH-ZZ-1589980          ZZ  ZZ20240526BOMDEL2019.0   \n","1070  INV-ZZ-3445620  SCH-ZZ-6544056          ZZ  ZZ20240527BOMDEL3869.0   \n","819   INV-ZZ-2885495  SCH-ZZ-1589980          ZZ  ZZ20240527BOMDEL2019.0   \n","820   INV-ZZ-2737988  SCH-ZZ-1589980          ZZ  ZZ20240529BOMDEL2019.0   \n","821   INV-ZZ-4794087  SCH-ZZ-1589980          ZZ  ZZ20240530BOMDEL2019.0   \n","822   INV-ZZ-5260527  SCH-ZZ-1589980          ZZ  ZZ20240531BOMDEL2019.0   \n","823   INV-ZZ-2785213  SCH-ZZ-1589980          ZZ  ZZ20240601BOMDEL2019.0   \n","824   INV-ZZ-1438693  SCH-ZZ-1589980          ZZ  ZZ20240602BOMDEL2019.0   \n","825   INV-ZZ-5390033  SCH-ZZ-1589980          ZZ  ZZ20240603BOMDEL2019.0   \n","826   INV-ZZ-7775573  SCH-ZZ-1589980          ZZ  ZZ20240605BOMDEL2019.0   \n","\n","      FlightNumber     AircraftType DepartureDate   DepartureDateTime  \\\n","1060        3869.0          BAe 146    04/22/2024 2024-04-22 07:20:00   \n","789         2019.0  Airbus A320 Neo    04/22/2024 2024-04-22 16:42:00   \n","790         2019.0  Airbus A320 Neo    04/24/2024 2024-04-24 16:42:00   \n","791         2019.0  Airbus A320 Neo    04/25/2024 2024-04-25 16:42:00   \n","792         2019.0  Airbus A320 Neo    04/26/2024 2024-04-26 16:42:00   \n","1061        3869.0          BAe 146    04/27/2024 2024-04-27 07:20:00   \n","793         2019.0  Airbus A320 Neo    04/27/2024 2024-04-27 16:42:00   \n","794         2019.0  Airbus A320 Neo    04/28/2024 2024-04-28 16:42:00   \n","1062        3869.0          BAe 146    04/29/2024 2024-04-29 07:20:00   \n","795         2019.0  Airbus A320 Neo    04/29/2024 2024-04-29 16:42:00   \n","796         2019.0  Airbus A320 Neo    05/01/2024 2024-05-01 16:42:00   \n","797         2019.0  Airbus A320 Neo    05/02/2024 2024-05-02 16:42:00   \n","798         2019.0  Airbus A320 Neo    05/03/2024 2024-05-03 16:42:00   \n","1063        3869.0          BAe 146    05/04/2024 2024-05-04 07:20:00   \n","799         2019.0  Airbus A320 Neo    05/04/2024 2024-05-04 16:42:00   \n","800         2019.0  Airbus A320 Neo    05/05/2024 2024-05-05 16:42:00   \n","1064        3869.0          BAe 146    05/06/2024 2024-05-06 07:20:00   \n","801         2019.0  Airbus A320 Neo    05/06/2024 2024-05-06 16:42:00   \n","802         2019.0  Airbus A320 Neo    05/08/2024 2024-05-08 16:42:00   \n","803         2019.0  Airbus A320 Neo    05/09/2024 2024-05-09 16:42:00   \n","804         2019.0  Airbus A320 Neo    05/10/2024 2024-05-10 16:42:00   \n","1065        3869.0          BAe 146    05/11/2024 2024-05-11 07:20:00   \n","805         2019.0  Airbus A320 Neo    05/11/2024 2024-05-11 16:42:00   \n","806         2019.0  Airbus A320 Neo    05/12/2024 2024-05-12 16:42:00   \n","1066        3869.0          BAe 146    05/13/2024 2024-05-13 07:20:00   \n","807         2019.0  Airbus A320 Neo    05/13/2024 2024-05-13 16:42:00   \n","808         2019.0  Airbus A320 Neo    05/15/2024 2024-05-15 16:42:00   \n","809         2019.0  Airbus A320 Neo    05/16/2024 2024-05-16 16:42:00   \n","810         2019.0  Airbus A320 Neo    05/17/2024 2024-05-17 16:42:00   \n","1067        3869.0          BAe 146    05/18/2024 2024-05-18 07:20:00   \n","811         2019.0  Airbus A320 Neo    05/18/2024 2024-05-18 16:42:00   \n","812         2019.0  Airbus A320 Neo    05/19/2024 2024-05-19 16:42:00   \n","1068        3869.0          BAe 146    05/20/2024 2024-05-20 07:20:00   \n","813         2019.0  Airbus A320 Neo    05/20/2024 2024-05-20 16:42:00   \n","814         2019.0  Airbus A320 Neo    05/22/2024 2024-05-22 16:42:00   \n","815         2019.0  Airbus A320 Neo    05/23/2024 2024-05-23 16:42:00   \n","816         2019.0  Airbus A320 Neo    05/24/2024 2024-05-24 16:42:00   \n","1069        3869.0          BAe 146    05/25/2024 2024-05-25 07:20:00   \n","817         2019.0  Airbus A320 Neo    05/25/2024 2024-05-25 16:42:00   \n","818         2019.0  Airbus A320 Neo    05/26/2024 2024-05-26 16:42:00   \n","1070        3869.0          BAe 146    05/27/2024 2024-05-27 07:20:00   \n","819         2019.0  Airbus A320 Neo    05/27/2024 2024-05-27 16:42:00   \n","820         2019.0  Airbus A320 Neo    05/29/2024 2024-05-29 16:42:00   \n","821         2019.0  Airbus A320 Neo    05/30/2024 2024-05-30 16:42:00   \n","822         2019.0  Airbus A320 Neo    05/31/2024 2024-05-31 16:42:00   \n","823         2019.0  Airbus A320 Neo    06/01/2024 2024-06-01 16:42:00   \n","824         2019.0  Airbus A320 Neo    06/02/2024 2024-06-02 16:42:00   \n","825         2019.0  Airbus A320 Neo    06/03/2024 2024-06-03 16:42:00   \n","826         2019.0  Airbus A320 Neo    06/05/2024 2024-06-05 16:42:00   \n","\n","         ArrivalDateTime DepartureAirport  ... PC_AvailableInventory  \\\n","1060 2024-04-22 09:24:00              BOM  ...                     0   \n","789  2024-04-23 04:40:00              BOM  ...                     0   \n","790  2024-04-25 04:40:00              BOM  ...                    25   \n","791  2024-04-26 04:40:00              BOM  ...                    25   \n","792  2024-04-27 04:40:00              BOM  ...                    26   \n","1061 2024-04-27 09:24:00              BOM  ...                    12   \n","793  2024-04-28 04:40:00              BOM  ...                    28   \n","794  2024-04-29 04:40:00              BOM  ...                    30   \n","1062 2024-04-29 09:24:00              BOM  ...                    13   \n","795  2024-04-30 04:40:00              BOM  ...                    27   \n","796  2024-05-02 04:40:00              BOM  ...                    27   \n","797  2024-05-03 04:40:00              BOM  ...                    26   \n","798  2024-05-04 04:40:00              BOM  ...                    31   \n","1063 2024-05-04 09:24:00              BOM  ...                    13   \n","799  2024-05-05 04:40:00              BOM  ...                    29   \n","800  2024-05-06 04:40:00              BOM  ...                    29   \n","1064 2024-05-06 09:24:00              BOM  ...                    14   \n","801  2024-05-07 04:40:00              BOM  ...                    25   \n","802  2024-05-09 04:40:00              BOM  ...                    27   \n","803  2024-05-10 04:40:00              BOM  ...                    29   \n","804  2024-05-11 04:40:00              BOM  ...                    30   \n","1065 2024-05-11 09:24:00              BOM  ...                    14   \n","805  2024-05-12 04:40:00              BOM  ...                    30   \n","806  2024-05-13 04:40:00              BOM  ...                    30   \n","1066 2024-05-13 09:24:00              BOM  ...                    15   \n","807  2024-05-14 04:40:00              BOM  ...                    31   \n","808  2024-05-16 04:40:00              BOM  ...                    28   \n","809  2024-05-17 04:40:00              BOM  ...                    31   \n","810  2024-05-18 04:40:00              BOM  ...                    34   \n","1067 2024-05-18 09:24:00              BOM  ...                    16   \n","811  2024-05-19 04:40:00              BOM  ...                    31   \n","812  2024-05-20 04:40:00              BOM  ...                    32   \n","1068 2024-05-20 09:24:00              BOM  ...                    16   \n","813  2024-05-21 04:40:00              BOM  ...                    33   \n","814  2024-05-23 04:40:00              BOM  ...                    29   \n","815  2024-05-24 04:40:00              BOM  ...                    29   \n","816  2024-05-25 04:40:00              BOM  ...                    33   \n","1069 2024-05-25 09:24:00              BOM  ...                    15   \n","817  2024-05-26 04:40:00              BOM  ...                    35   \n","818  2024-05-27 04:40:00              BOM  ...                    30   \n","1070 2024-05-27 09:24:00              BOM  ...                    15   \n","819  2024-05-28 04:40:00              BOM  ...                    33   \n","820  2024-05-30 04:40:00              BOM  ...                    34   \n","821  2024-05-31 04:40:00              BOM  ...                    32   \n","822  2024-06-01 04:40:00              BOM  ...                    34   \n","823  2024-06-02 04:40:00              BOM  ...                    33   \n","824  2024-06-03 04:40:00              BOM  ...                    32   \n","825  2024-06-04 04:40:00              BOM  ...                    32   \n","826  2024-06-06 04:40:00              BOM  ...                    34   \n","\n","      EC_TotalInventory  EC_BookedInventory  EC_Oversold  \\\n","1060                 42                  26           10   \n","789                  83                  51           21   \n","790                  83                  50           22   \n","791                  81                  48           24   \n","792                  82                  49           23   \n","1061                 43                  26           10   \n","793                  83                  47           25   \n","794                  82                  43           29   \n","1062                 42                  26           10   \n","795                  84                  47           25   \n","796                  80                  47           25   \n","797                  86                  48           24   \n","798                  86                  45           27   \n","1063                 43                  24           12   \n","799                  85                  47           25   \n","800                  82                  43           29   \n","1064                 43                  23           13   \n","801                  84                  49           23   \n","802                  86                  48           24   \n","803                  81                  45           27   \n","804                  85                  45           27   \n","1065                 41                  23           13   \n","805                  85                  43           29   \n","806                  80                  43           29   \n","1066                 42                  22           14   \n","807                  81                  40           32   \n","808                  83                  45           27   \n","809                  85                  41           31   \n","810                  83                  40           32   \n","1067                 40                  21           15   \n","811                  81                  40           32   \n","812                  82                  39           33   \n","1068                 42                  21           15   \n","813                  81                  40           32   \n","814                  81                  44           28   \n","815                  84                  44           28   \n","816                  81                  39           33   \n","1069                 42                  22           14   \n","817                  79                  36           36   \n","818                  83                  42           30   \n","1070                 43                  22           14   \n","819                  82                  39           33   \n","820                  83                  38           34   \n","821                  86                  43           29   \n","822                  80                  37           35   \n","823                  81                  38           34   \n","824                  83                  39           33   \n","825                  84                  40           32   \n","826                  81                  38           34   \n","\n","      EC_AvailableInventory              FC_CD                        BC_CD  \\\n","1060                      0   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","789                       3  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","790                      33  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","791                      33  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","792                      33  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1061                     17   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","793                      36  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","794                      39  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1062                     16   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","795                      37  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","796                      33  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","797                      38  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","798                      41  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1063                     19   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","799                      38  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","800                      39  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1064                     20   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","801                      35  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","802                      38  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","803                      36  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","804                      40  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1065                     18   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","805                      42  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","806                      37  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1066                     20   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","807                      41  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","808                      38  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","809                      44  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","810                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1067                     19   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","811                      41  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","812                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1068                     21   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","813                      41  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","814                      37  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","815                      40  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","816                      42  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1069                     20   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","817                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","818                      41  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","1070                     21   {'F': 5, 'P': 4}     {'C': 7, 'J': 5, 'Z': 5}   \n","819                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","820                      45  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","821                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","822                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","823                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","824                      44  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","825                      44  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","826                      43  {'F': 11, 'P': 7}  {'C': 14, 'J': 11, 'Z': 11}   \n","\n","                                                  PC_CD  \\\n","1060   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","789   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","790   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","791   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","792   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1061   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","793   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","794   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1062   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","795   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","796   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","797   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","798   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1063   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","799   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","800   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1064   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","801   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","802   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","803   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","804   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1065   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","805   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","806   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1066   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","807   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","808   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","809   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","810   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1067   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","811   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","812   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1068   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","813   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","814   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","815   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","816   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1069   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","817   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","818   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","1070   {'Q': 8, 'R': 5, 'S': 3, 'T': 3, 'H': 5, 'M': 3}   \n","819   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","820   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","821   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","822   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","823   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","824   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","825   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","826   {'Q': 16, 'R': 11, 'S': 5, 'T': 5, 'H': 11, 'M...   \n","\n","                                                  EC_CD  \\\n","1060  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","789   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","790   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","791   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","792   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1061  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","793   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","794   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1062  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","795   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","796   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","797   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","798   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1063  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","799   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","800   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1064  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","801   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","802   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","803   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","804   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1065  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","805   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","806   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1066  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","807   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","808   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","809   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","810   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1067  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","811   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","812   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1068  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","813   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","814   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","815   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","816   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1069  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","817   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","818   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","1070  {'Y': 3, 'A': 3, 'B': 1, 'D': 1, 'E': 1, 'G': ...   \n","819   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","820   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","821   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","822   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","823   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","824   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","825   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","826   {'Y': 5, 'A': 5, 'B': 3, 'D': 3, 'E': 3, 'G': ...   \n","\n","      Arrival_TimeDifference  \n","1060                4.733333  \n","789                24.000000  \n","790                72.000000  \n","791                96.000000  \n","792               120.000000  \n","1061              124.733333  \n","793               144.000000  \n","794               168.000000  \n","1062              172.733333  \n","795               192.000000  \n","796               240.000000  \n","797               264.000000  \n","798               288.000000  \n","1063              292.733333  \n","799               312.000000  \n","800               336.000000  \n","1064              340.733333  \n","801               360.000000  \n","802               408.000000  \n","803               432.000000  \n","804               456.000000  \n","1065              460.733333  \n","805               480.000000  \n","806               504.000000  \n","1066              508.733333  \n","807               528.000000  \n","808               576.000000  \n","809               600.000000  \n","810               624.000000  \n","1067              628.733333  \n","811               648.000000  \n","812               672.000000  \n","1068              676.733333  \n","813               696.000000  \n","814               744.000000  \n","815               768.000000  \n","816               792.000000  \n","1069              796.733333  \n","817               816.000000  \n","818               840.000000  \n","1070              844.733333  \n","819               864.000000  \n","820               912.000000  \n","821               936.000000  \n","822               960.000000  \n","823               984.000000  \n","824              1008.000000  \n","825              1032.000000  \n","826              1080.000000  \n","\n","[49 rows x 41 columns]\n"]}]},{"cell_type":"code","source":["number_of_affected_PNRs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5icEwoX5iS-_","executionInfo":{"status":"ok","timestamp":1702637970627,"user_tz":-330,"elapsed":422,"user":{"displayName":"Team-69","userId":"15141329460336760271"}},"outputId":"5d1e3724-7ec6-4620-908f-19d640b4fe07"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"8zIdp6B0IaA6"},"execution_count":null,"outputs":[]}]}